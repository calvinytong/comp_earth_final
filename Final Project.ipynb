{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from descartes.patch import PolygonPatch \n",
    "from matplotlib.patches import Polygon\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.transform import rescale\n",
    "import skimage.color as color\n",
    "import image_slicer\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for interacting with the sat images\n",
    "# Adapted from https://www.kaggle.com/gabrielaltay/polygons-over-images-and-5x5-mosaics/code\n",
    "N_CHANNELS = {'3': 3, 'A': 8, 'M': 8, 'P': 1}\n",
    "\n",
    "\n",
    "class SatImageManager:\n",
    "    \"\"\"\n",
    "    Manager class wrapping code for interacting with the sat image dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: str\n",
    "        Path to the data. Assumed the folder is default from kaggle download\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir='data/'):\n",
    "        self.data_dir = data_dir\n",
    "        self.wkt_manager = WktManager(data_dir)\n",
    "        self.gs_manager = GridSizeManager(data_dir)\n",
    "\n",
    "        self.fnames3b = os.listdir(os.path.join(data_dir, 'three_band'))\n",
    "        self.fnames16b = os.listdir(os.path.join(data_dir, 'sixteen_band'))\n",
    "        \n",
    "    def get_fname(self, image_id, band):\n",
    "        \"\"\"\n",
    "        Get filename from image_id and band level\n",
    "        \"\"\"\n",
    "        if band == '3':\n",
    "            fname = '{}/three_band/{}.tif'.format(\n",
    "                self.data_dir, image_id)\n",
    "        elif band in ['A', 'M', 'P']:\n",
    "            fname = '{}/sixteen_band/{}_{}.tif'.format(\n",
    "                self.data_dir, image_id, band)\n",
    "        else:\n",
    "            raise ValueError('band must be one of [\"3\", \"A\", \"M\", \"P\"]')\n",
    "        return fname\n",
    "\n",
    "    def get_image_dimensions(self, image_id, band):\n",
    "        \"\"\"\n",
    "        Get image dimention from id and band label \n",
    "        \"\"\"\n",
    "        fname = self.get_fname(image_id, band)\n",
    "        with tiff.TiffFile(fname) as tfile:\n",
    "            shape = tfile.pages[0].shape\n",
    "        return shape\n",
    "\n",
    "    def return_image(self, image_id, band):\n",
    "        \"\"\"\n",
    "        Read image with the tifffile package\n",
    "        \"\"\"\n",
    "        fname = self.get_fname(image_id, band)\n",
    "        img = tiff.imread(fname)\n",
    "        return img\n",
    "    \n",
    "    def return_polygon_patches(self, image_id):\n",
    "        \"\"\"\n",
    "        Return a list of scaled polygon patches for given image\n",
    "        \"\"\"\n",
    "        poly_dict = self.return_scaled_polygons(image_id)\n",
    "        poly_list = []\n",
    "\n",
    "        for p in poly_dict:\n",
    "            for polygon in poly_dict[p]:\n",
    "                poly_list.append(Polygon(np.array(polygon.exterior), color=plt.cm.Set1(p), lw=0, alpha=1))\n",
    "                \n",
    "        return poly_list\n",
    "    \n",
    "    def return_scaled_polygons(self, image_id):\n",
    "        \"\"\"\n",
    "        Return dictionary of scaled polygons\n",
    "        \"\"\"\n",
    "        poly_dict = self.wkt_manager.return_polygon_dict(image_id)\n",
    "        _, w, h = self.get_image_dimensions(image_id, '3') \n",
    "        x_max, y_min = self.gs_manager.get_xmax_ymin(image_id)\n",
    "        for p in poly_dict:\n",
    "            w = w * (w/(w+1))\n",
    "            h = h * (h/(h+1))\n",
    "\n",
    "            x_scaler = w / x_max\n",
    "            y_scaler = h / y_min\n",
    "            poly_dict[p] = shapely.affinity.scale(poly_dict[p], xfact = x_scaler, yfact= y_scaler, origin=(0,0,0))\n",
    "        return poly_dict\n",
    "        \n",
    "    def return_plottable_image(self, image_id, band):\n",
    "        \"\"\"\n",
    "        Return image in plottable form\n",
    "        \"\"\"\n",
    "        image = self.return_image(image_id, band)\n",
    "        if band == '3':\n",
    "            image = np.rollaxis(image, 0, 3)\n",
    "            return self.stretch_8bit(image)\n",
    "        else:\n",
    "            # TODO do this for other band \n",
    "            return image     \n",
    "            \n",
    "    def return_side_by_side_figure(self, image_ids, band, save=False):\n",
    "        \"\"\"\n",
    "        Convenience for plotting image and polygons side by side\n",
    "        \"\"\"\n",
    "        for image_id in image_ids:\n",
    "            polygons = self.return_polygon_patches(image_id)\n",
    "            image = self.return_plottable_image(image_id, band)\n",
    "\n",
    "            fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(10, 10))\n",
    "            ax = axes.ravel()\n",
    "            ax[0].imshow(image)\n",
    "            ax[0].set_title(image_id)\n",
    "            ax[0].axis('off')\n",
    "            \n",
    "            ax[1].imshow(image)\n",
    "            for p in polygons:\n",
    "                ax[1].add_patch(p)\n",
    "            ax[1].set_title(image_id + 'labeled')\n",
    "            ax[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "    def pansharpen(self, image_id, method='browley', W=0.1, all_data=False):\n",
    "        \"\"\"\n",
    "        Adapted from https://www.kaggle.com/resolut/panchromatic-sharpening\n",
    "        Apply panchromatic sharpening to given image\n",
    "        http://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/fundamentals-of-panchromatic-sharpening.htm\n",
    "        \"\"\"\n",
    "        m = self.return_image(image_id, 'M')\n",
    "        pan = self.return_image(image_id, 'P')\n",
    "        \n",
    "        # get m_bands\n",
    "        rgbn = np.empty((m.shape[1], m.shape[2], 4)) \n",
    "        rgbn[:,:,0] = m[4,:,:] # red\n",
    "        rgbn[:,:,1] = m[2,:,:] # green\n",
    "        rgbn[:,:,2] = m[1,:,:] # blue\n",
    "        rgbn[:,:,3] = m[6,:,:] # NIR-1\n",
    "\n",
    "        # scaled them\n",
    "        rgbn_scaled = np.empty((m.shape[1]*4, m.shape[2]*4, 4))\n",
    "\n",
    "        for i in range(4):\n",
    "            img = rgbn[:,:,i]\n",
    "            scaled = rescale(img, (4,4))\n",
    "            rgbn_scaled[:,:,i] = scaled\n",
    "\n",
    "        # check size and crop for pan band\n",
    "        if pan.shape[0] < rgbn_scaled.shape[0]:\n",
    "            rgbn_scaled = rgbn_scaled[:pan.shape[0],:, :]\n",
    "        else:\n",
    "            pan = pan[:rgbn_scaled.shape[0], :]\n",
    "\n",
    "        if pan.shape[1] < rgbn_scaled.shape[1]:\n",
    "            rgbn_scaled = rgbn_scaled[:,:pan.shape[1], :]\n",
    "        else:\n",
    "            pan = pan[:,:rgbn_scaled.shape[1]]\n",
    "\n",
    "        R = rgbn_scaled[:,:,0]\n",
    "        G = rgbn_scaled[:,:,1]\n",
    "        B = rgbn_scaled[:,:,2]\n",
    "        I = rgbn_scaled[:,:,3]\n",
    "\n",
    "        image = None\n",
    "\n",
    "        if method == 'simple_browley':\n",
    "            all_in = R+G+B\n",
    "            prod = np.multiply(all_in, pan)\n",
    "\n",
    "            r = np.multiply(R, pan/all_in)[:, :, np.newaxis]\n",
    "            g = np.multiply(G, pan/all_in)[:, :, np.newaxis]\n",
    "            b = np.multiply(B, pan/all_in)[:, :, np.newaxis]\n",
    "\n",
    "            image = np.concatenate([r,g,b], axis=2)\n",
    "\n",
    "        if method == 'sample_mean':\n",
    "            r = 0.5 * (R + pan)[:, :, np.newaxis]\n",
    "            g = 0.5 * (G + pan)[:, :, np.newaxis]\n",
    "            b = 0.5 * (B + pan)[:, :, np.newaxis]\n",
    "\n",
    "            image = np.concatenate([r,g,b], axis=2)\n",
    "\n",
    "        if method == 'esri':\n",
    "            ADJ = pan-rgbn_scaled.mean(axis=2) \n",
    "            r = (R + ADJ)[:, :, np.newaxis]\n",
    "            g = (G + ADJ)[:, :, np.newaxis]\n",
    "            b = (B + ADJ)[:, :, np.newaxis]\n",
    "            i = (I + ADJ)[:, :, np.newaxis]\n",
    "\n",
    "            image = np.concatenate([r,g,b,i], axis=2)\n",
    "\n",
    "        if method == 'browley':\n",
    "            DNF = (pan - W*I)/(W*R+W*G+W*B)\n",
    "\n",
    "            r = (R * DNF)[:, :, np.newaxis]\n",
    "            g = (G * DNF)[:, :, np.newaxis]\n",
    "            b = (B * DNF)[:, :, np.newaxis]\n",
    "            i = (I * DNF)[:, :, np.newaxis]\n",
    "\n",
    "            image = np.concatenate([r,g,b,i], axis=2)\n",
    "\n",
    "        if method == 'hsv':\n",
    "            hsv = color.rgb2hsv(rgbn_scaled[:,:,:3])\n",
    "            hsv[:,:,2] = pan - I*W\n",
    "            image = color.hsv2rgb(hsv)\n",
    "\n",
    "        if all_data:\n",
    "            return rgbn_scaled, image, I\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def stretch_8bit(self, bands, lower_percent=2, higher_percent=98):\n",
    "        \"\"\"\n",
    "        Matplotlib doesn't support viewing 16 bit images, so we convert\n",
    "        to 8 bit here. Note: Some information will be lost\n",
    "        \"\"\"\n",
    "        out = np.zeros_like(bands).astype(np.float32)\n",
    "        for i in range(3):\n",
    "            a = 0 \n",
    "            b = 1 \n",
    "            c = np.percentile(bands[:,:,i], lower_percent)\n",
    "            d = np.percentile(bands[:,:,i], higher_percent)        \n",
    "            t = a + (bands[:,:,i] - c) * (b - a) / (d - c)    \n",
    "            t[t<a] = a\n",
    "            t[t>b] = b\n",
    "            out[:,:,i] =t\n",
    "        return out.astype(np.float32)\n",
    "\n",
    "\n",
    "class WktManager:\n",
    "    \"\"\"Handles the training labels (polygons in wkt format)\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir='data/', fname='train_wkt_v4.csv'):\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.image_ids = self.df['ImageId'].unique()\n",
    "\n",
    "    def return_image_df(self, image_id):\n",
    "        \"\"\"\n",
    "        Get data frame from image\n",
    "        \"\"\"\n",
    "        bmask = self.df['ImageId']==image_id\n",
    "        return self.df[bmask]\n",
    "\n",
    "    def return_polygon_dict(self, image_id):\n",
    "        \"\"\"\n",
    "        Return polygon dict for given image from the data frame\n",
    "        \"\"\"\n",
    "        polygon_dict = {}\n",
    "        image = self.return_image_df(image_id)\n",
    "        for c_type in image.ClassType.unique():\n",
    "            polygon_dict[c_type] = wkt.loads(image[image.ClassType == c_type].MultipolygonWKT.values[0])\n",
    "        return polygon_dict\n",
    "    \n",
    "    \n",
    "class GridSizeManager:\n",
    "    \"\"\"Handles the geo-coordinates from the grid sizes file.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir='data/', fname='grid_sizes.csv'):\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        self.df = pd.read_csv(\n",
    "            path, names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
    "\n",
    "    def get_xmax_ymin(self, image_id):\n",
    "        \"\"\"\n",
    "        Get xmax and ymin for polygon scaling\n",
    "        \"\"\"\n",
    "        bmask = self.df['ImageId']==image_id\n",
    "        xmax_ymin = self.df.loc[bmask, ['Xmax', 'Ymin']].iloc[0].to_dict()\n",
    "        return xmax_ymin['Xmax'], xmax_ymin['Ymin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(im_manager, save_path, dpi=1200, method='hsv', W=0.1):\n",
    "    \"\"\"\n",
    "    Generate A-B traning data. Creates folders A and B and save path and puts\n",
    "    generated images into it.\n",
    "    \"\"\"\n",
    "    a_path = os.path.join(save_path, 'A')\n",
    "    b_path = os.path.join(save_path, 'B')\n",
    "    \n",
    "    overwrite_folder_at_path(a_path)\n",
    "    overwrite_folder_at_path(b_path)\n",
    "    \n",
    "    for image_id in im_manager.wkt_manager.image_ids:\n",
    "        \n",
    "        # Sharpened image\n",
    "        sharpened = im_manager.pansharpen(image_id, method=method, W=W) \n",
    "        \n",
    "        # Generate the map figure\n",
    "        fig = plt.figure(figsize=(sharpened.shape[0]/dpi,sharpened.shape[1]/dpi), dpi=dpi)\n",
    "        im = plt.imshow(im_manager.stretch_8bit(sharpened), aspect='auto')\n",
    "        plt.axis('off')\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        plt.savefig(os.path.join(a_path, image_id + '.png'), bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Generate the poly figure\n",
    "        fig = plt.figure(figsize=(sharpened.shape[0]/dpi,sharpened.shape[1]/dpi), dpi=dpi)\n",
    "        im = plt.imshow(np.zeros_like(sharpened), aspect='auto')\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        polygons = im_manager.return_polygon_patches(image_id)\n",
    "        for p in polygons:\n",
    "            ax.add_patch(p)\n",
    "        plt.axis('off')\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        plt.savefig(os.path.join(b_path, image_id + '.png'), bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "        plt.close(fig)\n",
    "\n",
    "        \n",
    "def plot_image_figure(im_manager, image_id):\n",
    "    \"\"\"\n",
    "    Convenience function for plotting an image\n",
    "    \"\"\"\n",
    "    sharpened = im_manager.pansharpen(image_id, method='hsv', W=0.4)\n",
    "    fig = plt.figure(figsize=(50, 50))\n",
    "    im = plt.imshow(im_manager.stretch_8bit(sharpened), aspect='auto')\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_polygon_figure(im_manager, image_id, image_dim, save_path=''):\n",
    "    \"\"\"\n",
    "    Convenience function for plotting polygon images\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(50,50))\n",
    "    plt.imshow(np.zeros(image_dim), aspect='auto')\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Plot polygons\n",
    "    polygons = im_manager.return_polygon_patches(image_id)\n",
    "    for p in polygons:\n",
    "        ax.add_patch(p)\n",
    "    plt.axis('off')\n",
    "\n",
    "        \n",
    "def segment_training_data(save_path, num_segments=10):\n",
    "    \"\"\"\n",
    "    Segment original images into equal slices. Saves the segments into A/sliced and B/sliced\n",
    "    \"\"\"\n",
    "    # Path for images created by generate_training_data\n",
    "    a_path = os.path.join(save_path, 'A')\n",
    "    b_path = os.path.join(save_path, 'B')\n",
    "    \n",
    "    # Path for sliced images\n",
    "    a_slice_path = os.path.join(a_path, 'sliced')\n",
    "    b_slice_path = os.path.join(b_path, 'sliced')\n",
    "\n",
    "    # Write slice path\n",
    "    overwrite_folder_at_path(a_slice_path)\n",
    "    overwrite_folder_at_path(b_slice_path)\n",
    "\n",
    "    file_names = []\n",
    "    \n",
    "    # Assume the file names in \n",
    "    # both directories match exactly\n",
    "    # so we only scan the directory once\n",
    "    for file in os.listdir(a_path):\n",
    "        if file.endswith('.png'):\n",
    "            file_names.append(file)\n",
    "    \n",
    "    for f in file_names:\n",
    "        # Slice and save to slice path\n",
    "        a_tiles = image_slicer.slice(os.path.join(a_path, f), num_segments, save=False)\n",
    "        b_tiles = image_slicer.slice(os.path.join(b_path, f), num_segments, save=False)\n",
    "        # Save with prefix of previous filename stipped of .png\n",
    "        image_slicer.save_tiles(a_tiles, prefix=f[:-4], directory=a_slice_path)\n",
    "        image_slicer.save_tiles(b_tiles, prefix=f[:-4], directory=b_slice_path)\n",
    "        \n",
    "def train_test_split(save_path, pic_dir='sliced', valid_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Generate train test split from segmented training data. Saves the splites into\n",
    "    A/train A/test A/valid\n",
    "    B/train B/test/ B/valid\n",
    "    This format allows pix2pix to generate a valid dataset from the images\n",
    "    \"\"\"\n",
    "    a_path = os.path.join(save_path, 'A')\n",
    "    b_path = os.path.join(save_path, 'B')\n",
    "    \n",
    "    a_slice_path = os.path.join(a_path, pic_dir)\n",
    "    b_slice_path = os.path.join(b_path, pic_dir)\n",
    "    \n",
    "    a_train_path = os.path.join(a_path, 'train')\n",
    "    a_test_path = os.path.join(a_path, 'test')\n",
    "    a_valid_path = os.path.join(a_path, 'valid')\n",
    "    \n",
    "    b_train_path = os.path.join(b_path, 'train')\n",
    "    b_test_path = os.path.join(b_path, 'test')\n",
    "    b_valid_path = os.path.join(b_path, 'valid')\n",
    "    \n",
    "    overwrite_folder_at_path(a_train_path)\n",
    "    overwrite_folder_at_path(a_test_path)\n",
    "    overwrite_folder_at_path(a_valid_path)\n",
    "    \n",
    "    overwrite_folder_at_path(b_train_path)\n",
    "    overwrite_folder_at_path(b_test_path)\n",
    "    overwrite_folder_at_path(b_valid_path)\n",
    "    \n",
    "    a_file_names = []\n",
    "    b_file_names = []\n",
    "    \n",
    "    for file in os.listdir(a_slice_path):\n",
    "        if file.endswith('.png'):\n",
    "            a_file_names.append(file)\n",
    "    \n",
    "    for file in os.listdir(b_slice_path):\n",
    "        if file.endswith('.png'):\n",
    "            b_file_names.append(file)\n",
    "    \n",
    "    a_file_names = sorted(a_file_names)\n",
    "    b_file_names = sorted(b_file_names)\n",
    "    \n",
    "    a_train, a_test, b_train, b_test = sk_train_test_split(a_file_names, b_file_names, test_size=test_ratio)\n",
    "    a_train, a_val, b_train, b_val = sk_train_test_split(a_train, b_train, test_size=valid_ratio)\n",
    "    \n",
    "    move_files(a_slice_path, a_train_path, a_train)\n",
    "    move_files(a_slice_path, a_valid_path, a_val)\n",
    "    move_files(a_slice_path, a_test_path, a_test)\n",
    "    move_files(b_slice_path, b_train_path, b_train)\n",
    "    move_files(b_slice_path, b_valid_path, b_val)\n",
    "    move_files(b_slice_path, b_test_path, b_test)\n",
    "\n",
    "\n",
    "def move_files(src, dst, filenames):\n",
    "    \"\"\"\n",
    "    move an array of filenames from a src to dst directory\n",
    "    \"\"\"\n",
    "    for f in filenames:\n",
    "        shutil.move(os.path.join(src, f), os.path.join(dst, f))\n",
    "    \n",
    "        \n",
    "def overwrite_folder_at_path(path):\n",
    "    \"\"\"\n",
    "    Danger! Hard overwrite of a directoy at given path\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segement Training Data Generation\n",
    "save_path = 'training_data'\n",
    "im_manager = SatImageManager()\n",
    "generate_training_data(im_manager, save_path)\n",
    "segment_training_data(save_path)\n",
    "train_test_split(save_path, pic_dir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calvin/miniconda3/envs/pytorch/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/calvin/miniconda3/envs/pytorch/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/home/calvin/miniconda3/envs/pytorch/lib/python3.6/site-packages/skimage/color/colorconv.py:278: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 2. + (arr[idx, 2] - arr[idx, 0]) / delta[idx]\n"
     ]
    }
   ],
   "source": [
    "# Panchromatic sharpening crossval\n",
    "methods = ['ESRI', 'browley', 'hsv']\n",
    "save_path = 'training_data'\n",
    "im_manager = SatImageManager()\n",
    "for m in methods:\n",
    "    generate_training_data(im_manager, save_path + '_' + m)\n",
    "    segment_training_data(save_path + '_' + m)\n",
    "    train_test_split(save_path, pic_dir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
